{"cells":[{"cell_type":"code","source":["!git clone https://github.com/prlabu/Speech-Articulatory-Coding.git"],"metadata":{"id":"2jXc8M9OyRZe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740606658892,"user_tz":300,"elapsed":3051,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}},"outputId":"4637f57f-092e-4d40-8eea-ad2a8b914a59"},"id":"2jXc8M9OyRZe","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Speech-Articulatory-Coding'...\n","remote: Enumerating objects: 145, done.\u001b[K\n","remote: Counting objects: 100% (145/145), done.\u001b[K\n","remote: Compressing objects: 100% (97/97), done.\u001b[K\n","remote: Total 145 (delta 66), reused 111 (delta 37), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (145/145), 25.76 MiB | 29.81 MiB/s, done.\n","Resolving deltas: 100% (66/66), done.\n"]}]},{"cell_type":"code","source":["!pip install -e /content/Speech-Articulatory-Coding/."],"metadata":{"id":"YyEYj2mJylxs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740606665406,"user_tz":300,"elapsed":6513,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}},"outputId":"d644d006-2e87-4feb-f7e6-8757485c4361"},"id":"YyEYj2mJylxs","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/Speech-Articulatory-Coding\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (1.26.4)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (0.13.1)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (0.10.2.post1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (2.5.1+cpu)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (2.5.1+cpu)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (4.48.3)\n","Collecting torchcrepe (from speech-articulatory-coding==0.1.0)\n","  Downloading torchcrepe-0.0.23-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (0.28.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (3.10.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speech-articulatory-coding==0.1.0) (4.67.1)\n","Collecting penn (from speech-articulatory-coding==0.1.0)\n","  Downloading penn-0.0.14-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speech-articulatory-coding==0.1.0) (3.17.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speech-articulatory-coding==0.1.0) (2025.2.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speech-articulatory-coding==0.1.0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speech-articulatory-coding==0.1.0) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speech-articulatory-coding==0.1.0) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speech-articulatory-coding==0.1.0) (4.12.2)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (3.0.1)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (1.6.1)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (5.1.1)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (0.61.0)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (0.5.0.post1)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->speech-articulatory-coding==0.1.0) (1.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->speech-articulatory-coding==0.1.0) (1.17.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speech-articulatory-coding==0.1.0) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speech-articulatory-coding==0.1.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speech-articulatory-coding==0.1.0) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speech-articulatory-coding==0.1.0) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speech-articulatory-coding==0.1.0) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speech-articulatory-coding==0.1.0) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speech-articulatory-coding==0.1.0) (2.9.0.post0)\n","Collecting torchutil (from penn->speech-articulatory-coding==0.1.0)\n","  Downloading torchutil-0.0.14-py3-none-any.whl.metadata (24 kB)\n","Collecting yapecs (from penn->speech-articulatory-coding==0.1.0)\n","  Downloading yapecs-0.1.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->speech-articulatory-coding==0.1.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->speech-articulatory-coding==0.1.0) (3.1.5)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->speech-articulatory-coding==0.1.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->speech-articulatory-coding==0.1.0) (1.3.0)\n","Collecting resampy (from torchcrepe->speech-articulatory-coding==0.1.0)\n","  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->speech-articulatory-coding==0.1.0) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->speech-articulatory-coding==0.1.0) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->speech-articulatory-coding==0.1.0) (0.5.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->speech-articulatory-coding==0.1.0) (2.22)\n","Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->speech-articulatory-coding==0.1.0) (0.44.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->speech-articulatory-coding==0.1.0) (4.3.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->speech-articulatory-coding==0.1.0) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speech-articulatory-coding==0.1.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speech-articulatory-coding==0.1.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speech-articulatory-coding==0.1.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speech-articulatory-coding==0.1.0) (2025.1.31)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa->speech-articulatory-coding==0.1.0) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->speech-articulatory-coding==0.1.0) (3.0.2)\n","Collecting apprise (from torchutil->penn->speech-articulatory-coding==0.1.0)\n","  Downloading apprise-1.9.2-py3-none-any.whl.metadata (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from torchutil->penn->speech-articulatory-coding==0.1.0) (2.18.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from apprise->torchutil->penn->speech-articulatory-coding==0.1.0) (2.0.0)\n","Requirement already satisfied: click>=5.0 in /usr/local/lib/python3.11/dist-packages (from apprise->torchutil->penn->speech-articulatory-coding==0.1.0) (8.1.8)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from apprise->torchutil->penn->speech-articulatory-coding==0.1.0) (3.7)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchutil->penn->speech-articulatory-coding==0.1.0) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchutil->penn->speech-articulatory-coding==0.1.0) (1.70.0)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchutil->penn->speech-articulatory-coding==0.1.0) (5.29.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchutil->penn->speech-articulatory-coding==0.1.0) (75.1.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchutil->penn->speech-articulatory-coding==0.1.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchutil->penn->speech-articulatory-coding==0.1.0) (3.1.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib->apprise->torchutil->penn->speech-articulatory-coding==0.1.0) (3.2.2)\n","Downloading penn-0.0.14-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchcrepe-0.0.23-py3-none-any.whl (72.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchutil-0.0.14-py3-none-any.whl (22 kB)\n","Downloading yapecs-0.1.0-py3-none-any.whl (9.9 kB)\n","Downloading apprise-1.9.2-py3-none-any.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: yapecs, resampy, apprise, torchutil, torchcrepe, penn, speech-articulatory-coding\n","  Running setup.py develop for speech-articulatory-coding\n","Successfully installed apprise-1.9.2 penn-0.0.14 resampy-0.4.3 speech-articulatory-coding-0.1.0 torchcrepe-0.0.23 torchutil-0.0.14 yapecs-0.1.0\n"]}]},{"cell_type":"code","source":["import sys\n","import os\n","import glob\n","# sys.path.append(\"/content/Speech-Articulatory-Coding/\")\n","sys.path.insert(0,\"/content/Speech-Articulatory-Coding/\")\n"],"metadata":{"id":"19x71UXDyoJG","executionInfo":{"status":"ok","timestamp":1740606707675,"user_tz":300,"elapsed":41,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}}},"id":"19x71UXDyoJG","execution_count":4,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6N58Z1EgLVuG","executionInfo":{"status":"ok","timestamp":1740606708830,"user_tz":300,"elapsed":8,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}}},"id":"6N58Z1EgLVuG","execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"id":"ed8e3634-3e43-4d23-a881-d1d4201016c5","metadata":{"scrolled":true,"id":"ed8e3634-3e43-4d23-a881-d1d4201016c5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740606758938,"user_tz":300,"elapsed":49755,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}},"outputId":"2395d63b-1eb6-4ac3-e5dc-c2cd16c9ba0e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n","  warnings.warn(\n"]}],"source":["%load_ext autoreload\n","%autoreload 2\n","import importlib\n","# import sparc\n","from sparc import load_model\n","import copy\n","import os\n","import glob\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","import datetime"]},{"cell_type":"code","execution_count":6,"id":"e1db5055","metadata":{"id":"e1db5055","executionInfo":{"status":"ok","timestamp":1740606776621,"user_tz":300,"elapsed":59,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}}},"outputs":[],"source":["import soundfile as sf\n","import IPython.display as ipd\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","mpl.style.use('ggplot')"]},{"cell_type":"code","execution_count":14,"id":"5a636ebf","metadata":{"id":"5a636ebf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740606975127,"user_tz":300,"elapsed":5274,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}},"outputId":"284366ca-23bf-4042-e1e6-9b64137fa074"},"outputs":[{"output_type":"stream","name":"stdout","text":["load_model v3\n","load_model v3\n","Using PENN for pitch tracking.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n","  WeightNorm.apply(module, name, dim)\n"]}],"source":["coder = load_model(\"en\", device= \"xla\", use_penn=True)"]},{"cell_type":"code","execution_count":9,"id":"31541367","metadata":{"id":"31541367","executionInfo":{"status":"ok","timestamp":1740606814519,"user_tz":300,"elapsed":58,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}}},"outputs":[],"source":["# import sys\n","# # import scipy as sp\n","# import sklearn as skl\n","# from sklearn.decomposition import PCA\n","# import pandas as pd\n","\n","\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"NpEhvYMfy_9X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740606837954,"user_tz":300,"elapsed":23331,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}},"outputId":"5464f7f9-ab2c-4b0d-abee-74d46b9fdb82"},"id":"NpEhvYMfy_9X","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","id":"d7b16736-1ee7-4dce-b0aa-d51110548641","metadata":{"id":"d7b16736-1ee7-4dce-b0aa-d51110548641"},"source":["# Visualize EMA trajectories from wav"]},{"cell_type":"code","execution_count":null,"id":"d5498ecb","metadata":{"id":"d5498ecb"},"outputs":[],"source":["color_code = {\"UL\":mpl.colors.to_rgb(\"#EE3A5B\"),\n","              \"LL\":mpl.colors.to_rgb(\"#FFD155\"),\n","              \"LI\":mpl.colors.to_rgb(\"#959595\"),\n","              \"TT\":mpl.colors.to_rgb(\"#43B962\"),\n","              \"TB\":mpl.colors.to_rgb(\"#C44B9F\"),\n","              \"TD\":mpl.colors.to_rgb(\"#0093B7\"),\n","              \"Loudness\":mpl.colors.to_rgb(\"#FB754D\"),\n","              \"Pitch\":mpl.colors.to_rgb(\"#FB754D\"),}\n","\n","HPRC_channel_label = ['LIX','LIY','ULX','ULY','LLX','LLY','TTX','TTY','TBX','TBY','TDX','TDY']\n","\n","def plot_art(ax, art, gap=5, skip_y=False,color=None,alpha=1.0, lw=2, plot_velocity=False):\n","    yticks=[]\n","    ytick_labels=[]\n","    labels = [\"UL\",\"LL\", \"LI\", \"TT\", \"TB\", \"TD\"]\n","    chidxs = []\n","    HPRC_channel_label = ['LIX','LIY','ULX','ULY','LLX','LLY','TTX','TTY','TBX','TBY','TDX','TDY']\n","    channel_label = HPRC_channel_label\n","    for l in labels:\n","        chidxs.append(HPRC_channel_label.index(l+\"X\"))\n","        chidxs.append(HPRC_channel_label.index(l+\"Y\"))\n","\n","    time = np.arange(0, art.shape[0]) / 50\n","    # print(len(art))\n","    # print(time)\n","    for i, ch_i in enumerate(chidxs):\n","        ch_label = channel_label[ch_i]\n","        ytick_labels.append(ch_label)\n","        if ch_i < 12:\n","            art_name= ch_label[:2]\n","            if color is None:\n","                color = color_code[art_name]\n","        else:\n","            art_name = ch_label\n","            if color is None:\n","                color = color_code[art_name]\n","        x = art[:,ch_i]\n","        ax.plot(time, x-gap*i,color=color,alpha=alpha,lw=lw)\n","        if plot_velocity:\n","            ax.plot(time, 2*np.concatenate(([0], np.diff(x))) - gap*i,color='r',alpha=alpha*0.5,lw=1)\n","\n","        yticks.append(-gap*i)\n","\n","    i = i+1\n","    # diffs = np.diff(art, axis=0)\n","    # maxdiffs = np.max(diffs, axis = 1)\n","    diffs = np.vstack([np.zeros((1, 12)), np.abs(np.diff(art, axis=0))])\n","    maxdiffs = np.max(diffs, axis = 1)\n","    ax.plot(time, 2*maxdiffs-gap*i,color='r',alpha=alpha*0.5,lw=lw)\n","    yticks.append(-gap*i)\n","    ytick_labels.append('~max velocity')\n","\n","    if skip_y:\n","        ytick_labels = [\"\"]*len(ytick_labels)\n","\n","    ax.set_yticks(yticks,ytick_labels,fontsize=15)\n","\n","    # xticks= np.arange(0,len(art),50)\n","    # xtick_labels= [f\"{int(x*20/1000)}\" for x in xticks]\n","    # ax.set_xticks(xticks, xtick_labels,fontsize=15)\n","    ax.set_xlabel(\"Time (s)\", fontsize=15)\n","    # ax.set_xlim(0,len(art))\n","    return yticks"]},{"cell_type":"code","execution_count":null,"id":"31294788","metadata":{"id":"31294788"},"outputs":[],"source":["yticks=[]\n","ytick_labels=[]\n","labels = [\"UL\",\"LL\", \"LI\", \"TT\", \"TB\", \"TD\"]\n","chidxs = []\n","HPRC_channel_label = ['LIX','LIY','ULX','ULY','LLX','LLY','TTX','TTY','TBX','TBY','TDX','TDY']"]},{"cell_type":"code","execution_count":null,"id":"a79ba12e-2f91-41b5-8b94-88ceb52a33cf","metadata":{"id":"a79ba12e-2f91-41b5-8b94-88ceb52a33cf"},"outputs":[],"source":["# wav_file  = '../sample_audio/pataka-fast.wav'\n","wav_file  = '../sample_audio/be2d.wav'\n","wav_file2  = '../sample_audio/be2d-fran-trim-2.wav'\n","wav_file3  = '../sample_audio/be2d-chin-trim.wav'\n","\n","# wav_file  = '/Volumes/Nexus4/DBS/derivatives/sub-DM1033/aec/sub-DM1033_ses-intraop_task-lombard_run-03_recording-directionalmicaec_physio.wav'\n","# wav_file = '../sample_audio/sub-DM1033_ses-intraop_task-lombard_run-03_directionalmicaec-start-99s.wav'\n","\n","codes = [coder.encode(f) for f in [wav_file, wav_file2, wav_file3]]\n","# code = coder.encode(wav_file)\n","# code2 = coder.encode(wav_file2)\n","\n","# sound = out['wav']\n","# ema = out['ema'].squeeze()\n","\n","\n","        # x = art[:,ch_i]\n","        # ax.plot(time, np.concatenate(0, np.diff(x))-gap*i,color='r',alpha=alpha*0.5,lw=1)\n","        # ax.plot(time, x-gap*i,color=color,alpha=alpha,lw=lw)\n","# i = i+1\n","# diffs = np.vstack([np.zeros((1, 12)), np.diff(ema, axis=0)])\n","# maxdiffs = np.max(ema, axis = 1)\n","# ax.plot(time[2:-1], maxdiffs-gap*i,color=color,alpha=alpha,lw=lw)\n","# maxdiffs.shape\n","# maxdiffs.shape\n","\n","wav, wav_fs = sf.read(wav_file)\n","# # wav.size\n","\n","\n","# {k:v.shape for k, v in codes[1].items()}\n","# {k:v.shape for k, v in code.items()}\n"]},{"cell_type":"code","execution_count":null,"id":"cff539fc","metadata":{"id":"cff539fc"},"outputs":[],"source":["allacoustics = np.concatenate([c['acoustics_wvlm'] for c in codes], axis=0)\n","pca = PCA().fit(allacoustics)\n","plt.plot(np.cumsum(pca.explained_variance_ratio_))\n","\n","allacoustics_stats = pd.DataFrame({'min': np.amin(allacoustics, axis=0).T,\n","                                   'max': np.amax(allacoustics, axis=0).T})"]},{"cell_type":"code","execution_count":null,"id":"be28d782","metadata":{"id":"be28d782"},"outputs":[],"source":["codes[1]['loudness'].shape"]},{"cell_type":"code","execution_count":null,"id":"534293b8","metadata":{"id":"534293b8"},"outputs":[],"source":["acoustics_wvlm_tranformed = [pca.transform(c['acoustics_wvlm'])[:, 0:12] for c in codes]\n","for i, c in enumerate(codes):\n","    c.update({'acoustics_wvlm_transform': acoustics_wvlm_tranformed[i]})\n","#     c['acoustics_wvlm'] =\n","# acoustics_wvlm_tranformed[1].shape\n","# codes[1].keys()"]},{"cell_type":"code","execution_count":null,"id":"2f8b49c3","metadata":{"id":"2f8b49c3"},"outputs":[],"source":["offset = -100\n","# c = codes[2]\n","for c in codes:\n","    d = c['acoustics_wvlm_transform']\n","    plt.gca().set_prop_cycle(None)\n","    for i in range(d.shape[1]):\n","        plt.plot(d[:, i] + i*offset)\n","\n","plt.gca().set_yticks([])\n","plt.gca().set_ylabel('wavLM 1024-to-PCA dimensions')\n","plt.gca().set_xlabel('Time [sample]')"]},{"cell_type":"code","execution_count":null,"id":"e69a8ae0","metadata":{"id":"e69a8ae0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"749b92e9","metadata":{"id":"749b92e9"},"outputs":[],"source":["fig,ax = plt.subplots(3,1, figsize=(5,10), sharex=True)\n","\n","ax[0].plot(np.arange(0, wav.size) / wav_fs, wav)\n","\n","for code in codes:\n","    plot_art(ax[1], (code['ema']), color='C0', gap=6, alpha=0.5, lw=2)\n","# plot_art(ax[1], perturb_ema(code['ema']), color='C0', gap=6, alpha=0.5, lw=2)\n","# plot_art(ax[1], (code2['ema']), color='C0', gap=6, alpha=0.5, lw=1)\n","\n","\n","plt.show()"]},{"cell_type":"markdown","id":"7e87e531","metadata":{"id":"7e87e531"},"source":["# Simple encode-decode resynthesis"]},{"cell_type":"code","execution_count":null,"id":"1be7defc","metadata":{"id":"1be7defc"},"outputs":[],"source":["# TESTING\n","# wav_file = '../sample_audio/diva_babbling/diva_babbling-188.wav'\n","\n","# code_orig = coder.encode(wav_file)\n","# code_orig['acoustics_wvlm'].shape\n","\n","# wav = coder.decode(**code_orig)\n","# sf.write(wav_file[0:-4] + '-resynth.wav', wav, coder.sr)\n","\n","# # ground truth\n","# wavt,tsr = sf.read(wav_file)\n","# ipd.display(ipd.Audio(wavt, rate=tsr))\n","\n","# # resynthesized\n","# ipd.display(ipd.Audio(wav, rate=coder.sr))\n","\n","# code_orig.pop('wav', None)\n","# code_orig.keys()"]},{"cell_type":"code","execution_count":11,"id":"5bb49b15","metadata":{"id":"5bb49b15","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740606867780,"user_tz":300,"elapsed":15007,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}},"outputId":"06538dba-cadc-41f8-c7da-c8b8e62c3d4a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122528115.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122532286.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122536496.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122540567.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122544781.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122549036.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122553137.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122557200.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122601195.wav',\n"," '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling/diva_babbling-20250224122605233.wav']"]},"metadata":{},"execution_count":11}],"source":["# files = glob.glob('../sample_audio/diva_babbling/diva_babbling*.wav')\n","# topdir = '/projectnb/busplab/lbullock/sparc_sample_audio' # for BU SCC\n","topdir = '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding'\n","files = glob.glob(f'{topdir}/sample_audio/diva_babbling/diva_babbling*.wav')\n","\n","# dir_out = '../sample_audio/diva_babbling_resynth_20250224/'\n","# dir_out = '/content/drive/MyDrive/shbt/BML-guenther/2024S-guenther-audio-primitives/util/Speech-Articulatory-Coding/sample_audio/diva_babbling_resynth_20250224/'\n","dir_out = (f'{topdir}/sample_audio/diva_babbling_resynth/')\n","\n","files[0:10]\n"]},{"cell_type":"code","source":["\n","(fdir, fname) = os.path.split(files[0])\n","(fname, fext) = fname.split('.')\n","\n","code_orig = coder.encode(files[0])\n","# code_orig.pop('wav', None)\n","code_orig.keys()"],"metadata":{"id":"pJZLS9_B8bgR","colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"status":"error","timestamp":1740606940528,"user_tz":300,"elapsed":59593,"user":{"displayName":"Latane Bullock","userId":"14126567511653609834"}},"outputId":"3cf32c7f-c335-4a38-c073-76e4fd83052c"},"id":"pJZLS9_B8bgR","execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["_extract_ema: v4\n"]},{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-c8d0c34660d6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcode_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# code_orig.pop('wav', None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcode_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Speech-Articulatory-Coding/sparc/sparc.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, wavs, split_batch, reduce, include_acoustics, concat)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0minclude_acoustics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_acoustics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_acoustics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeaker_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft_len'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_lens\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Speech-Articulatory-Coding/sparc/src_extractor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wavfiles, outputs, split_batch)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mwavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_wavfiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_pitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msplit_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Speech-Articulatory-Coding/sparc/src_extractor.py\u001b[0m in \u001b[0;36m_extract_pitch\u001b[0;34m(self, wavs, outputs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mwavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_wavfiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_penn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mpitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodicity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_penn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mpitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodicity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_crepe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Speech-Articulatory-Coding/sparc/src_extractor.py\u001b[0m in \u001b[0;36m_run_penn\u001b[0;34m(self, wavs)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mpitches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mperiodicities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","source":["# encode and resynthesize a whole series of files\n","# for f in\n","\n","FS_SPARC_CODE = 50\n","SPARC_EMA_LABELS = [\"ULX\", \"ULY\", \"LLX\", \"LLY\",  \"LIX\", \"LIY\",  \"TTX\", \"TTY\", \"TBX\", \"TBY\", \"TDX\", \"TDY\"]\n","\n","\n"],"metadata":{"id":"3CI3X4Om_LUe"},"id":"3CI3X4Om_LUe","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"b3a654d0","metadata":{"id":"b3a654d0"},"outputs":[],"source":["\n","# files = glob.glob('../sample_audio/diva_babbling/diva_babbling*.wav')\n","files = glob.glob(f'{topdir}/sample_audio/diva_babbling/diva_babbling*.wav')\n","files = [f for f in files if '20250224' in f ]\n","\n","for idx_f, f in enumerate(files):\n","# f = files[0]\n","    print(idx_f, f)\n","    # if idx_f<500: % 500 files were run 20250225\n","    #   continue\n","\n","    (fdir, fname) = os.path.split(f)\n","    (fname, fext) = fname.split('.')\n","\n","    code_orig = coder.encode(f)\n","    code_orig.pop('wav', None)\n","\n","\n","    # write EMA\n","    code = code_orig['ema'].squeeze()\n","    code_time = np.arange(1, code.shape[0]+1)  / FS_SPARC_CODE\n","\n","    df = pd.DataFrame(code)\n","    df.columns = SPARC_EMA_LABELS\n","    df['file_id'] = fname\n","    df['time'] = code_time\n","    df.to_csv(dir_out + fname + '-resynth-ema.csv', index=False)\n","\n","    # write wavLM features\n","    code = code_orig['acoustics_wvlm'].squeeze()\n","    code_time = np.arange(1, code.shape[0]+1)  / FS_SPARC_CODE\n","    nfeat = code.shape[1]\n","\n","    df = pd.DataFrame(code)\n","    df.columns = [\"wavlm_\"+str(i) for i in range(0, nfeat)]\n","    df['file_id'] = fname\n","    df['time'] = code_time\n","    df.to_csv(dir_out + fname + '-resynth-wavlm.csv', index=False)\n","\n","    # write wav file\n","    wav = coder.decode(**code_orig)\n","    sf.write(dir_out + fname + '-resynth.wav', wav, coder.sr)\n","\n","    # write full pickle file\n","    with open(dir_out + fname + '-resynth.pickle', 'wb') as handle:\n","            pickle.dump(code_orig, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n"]},{"cell_type":"markdown","id":"4b07780a","metadata":{"id":"4b07780a"},"source":["# Learn the matrix W from prior samples"]},{"cell_type":"code","execution_count":null,"id":"36ed4107","metadata":{"id":"36ed4107"},"outputs":[],"source":["from sklearn.linear_model import SGDRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","files = glob.glob(f'{topdir}/sample_audio/diva_babbling/diva_babbling*.wav')\n","files = [f for f in files if '20250224' in f ]\n","\n","data_all = []\n","# Create an SGD-based OLS model\n","# model = SGDRegressor(max_iter=1000, tol=1e-3, eta0=0.0001, verbose=1, warm_start=True)\n","# model = LinearRegression()\n","# model = MultiOutputRegressor(model, n_jobs=-1)\n","\n","# score = np.zeros([13, 1])\n","# score[:] = np.nan\n","score = []\n","ibatch = 0\n","\n","for idx_f, f in enumerate(files):\n","\n","  if not (idx_f>=0 and idx_f<=251):\n","    continue\n","  # f = files[0]\n","  print(idx_f, f)\n","\n","  (fdir, fname) = os.path.split(f)\n","  (fname, fext) = fname.split('.')\n","\n","  diva = pd.read_csv(fdir + \"/\" + fname + '.csv')\n","\n","  fname_wavlm = dir_out + fname + '-resynth-wavlm.csv'\n","  if not os.path.exists(fname_wavlm):\n","      continue\n","  wavlm = pd.read_csv(fname_wavlm)\n","\n","  diva_interp = pd.DataFrame({'time': wavlm['time']})  # Keep B's time vector\n","\n","\n","  id_cols = ['time', 'file_id']\n","  for col in diva.columns:\n","      if col in id_cols:  # Skip 'time' column\n","          continue\n","      diva_interp[col] = np.interp(wavlm['time'], diva['time'], diva[col])\n","\n","  # Merge interpolated A with B\n","  df_merged = pd.merge(wavlm, diva_interp, how='inner', on='time')\n","  cols = id_cols + [col for col in df_merged.columns if col not in id_cols]\n","  df_merged = df_merged[cols]\n","\n","  data_all.append(df_merged)\n","\n","  # RUN LEAST SQUARES OR SGD-OLS\n","  if np.mod(idx_f, 30)==0 and idx_f!=0:\n","    print(f'Batch update: {ibatch}')\n","    df_data_all = pd.concat(data_all, ignore_index=True, axis=0)\n","\n","    cols_wavlm  = [col for col in df_data_all.columns if 'wavlm' in col]\n","    cols_diva = [col for col in df_data_all.columns if col not in cols_wavlm+id_cols]\n","\n","    X = df_data_all[cols_wavlm]\n","    Y = df_data_all[[col for col in cols_diva if col not in [\"Tension\", \"Pressure\", \"Voicing\"]]]\n","\n","    # Initialize scalers\n","    scaler_X = StandardScaler()\n","    scaler_Y = StandardScaler()\n","\n","    # Scale features\n","    # X = scaler_X.fit_transform(X)\n","    # Y = scaler_Y.fit_transform(Y)\n","\n","    if ibatch==0:\n","      print('Batch 0: fitting with OLS then SGD')\n","\n","      ols = LinearRegression()\n","      ols.fit(X, Y)\n","      # Initialize SGD\n","      base_sgd = SGDRegressor(max_iter=1000, tol=1e-3, warm_start=True, eta0=0.0001)\n","      model = MultiOutputRegressor(base_sgd, n_jobs=-1)\n","\n","      # model = LinearRegression()\n","      model.fit(X, Y)\n","\n","      # # Initialize SGD with warm_start=True\n","      # # Manually set coef_ and intercept_ for each output target\n","      # for i, est in enumerate(model.estimators_ if hasattr(model, 'estimators_') else []):\n","      #     est.coef_ = ols.coef_[i]  # Set the coefficient vector\n","      #     est.intercept_ = ols.intercept_[i]  # Set the intercept\n","\n","      # model.fit(X, Y, coef_init=ols.coef_.copy(), intercept_init=ols.intercept_.copy())\n","      # model.fit(X, Y)\n","\n","    else:\n","      print('Batch >0: fitting with SGD')\n","      model.partial_fit(X, Y) # if ibatch>=1 else\n","      # model.fit(X, Y) # Train incrementally\n","      # model.coef_ = (model.coef_ + model_last.coef_) / 2\n","      # model.intercept_ = (model.intercept_ + model_last.intercept_) / 2\n","\n","    # model.fit(X, Y)  # Train incrementally\n","    # score[0, ibatch] = model.score(X, Y)\n","\n","    Y_pred = model.predict(X)\n","\n","    resSS = ((Y - Y_pred)** 2).sum(axis=0)\n","    ySS = ((Y - Y.mean(axis=0)) ** 2).sum(axis=0)\n","    r2 = 1 - np.divide(resSS, ySS)\n","    r2['ns'] = X.shape[0]\n","\n","    score.append(r2)\n","    # score = pd.concat([score, r2], ignore_index=True, axis=0)\n","\n","    del data_all\n","    data_all = []\n","    ibatch += 1\n","    model_last = model\n","\n","  # out = np.linalg.lstsq(df_merged[cols_wavlm], df_data_all[cols_diva])\n","\n","\n","  # # verify that interpolation is correct d\n","  # fig, ax = plt.subplots(2, 1)\n","  # ax[0].plot(df_merged['time'], df_merged['Jaw'])\n","  # ax[0].plot(df_merged['time'], df_merged['Jaw']+0.05, alpha=0.5)\n","\n","# df_data_all = pd.concat(data_all, ignore_index=True, axis=0)\n","\n"]},{"cell_type":"code","source":["score"],"metadata":{"id":"jkgDH7U9Im7_"},"id":"jkgDH7U9Im7_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = pd.DataFrame(score)"],"metadata":{"id":"KyZOcuyPoKPo"},"id":"KyZOcuyPoKPo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["score"],"metadata":{"id":"iWYsHVkRJNzf"},"id":"iWYsHVkRJNzf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(score[[c for c in score.columns if c not in ['ns']]])"],"metadata":{"id":"7JB6dm-ZGF11"},"id":"7JB6dm-ZGF11","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save data to disk\n","# df_data_all['file_id'].nunique()\n","# df_data_all.to_csv(dir_out + 'df_data_all_wavlm-and-divaart-' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.csv', index=True)\n","\n"],"metadata":{"id":"-m4UAMpWDsJS"},"id":"-m4UAMpWDsJS","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"219b3387","metadata":{"id":"219b3387"},"outputs":[],"source":["# cols_wavlm  = [col for col in df_data_all.columns if 'wavlm' in col]\n","# cols_diva = [col for col in df_data_all.columns if col not in cols_wavlm+id_cols]\n","# out = np.linalg.lstsq(df_data_all[cols_wavlm], df_data_all[cols_diva])\n","\n","# save values to disk\n","W = model.coef_\n","pd.DataFrame.from_records(W).to_csv(dir_out + 'W_wavlm2divaart-' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.csv', index=True)\n","b = pd.DataFrame({'b': model.intercept_})\n","pd.DataFrame.from_records(b).to_csv(dir_out + 'Wb_wavlm2divaart-' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.csv', index=True)\n","b = model.intercept_\n"]},{"cell_type":"code","execution_count":null,"id":"4ef52e14","metadata":{"id":"4ef52e14"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"464d59d7","metadata":{"id":"464d59d7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"53fe5247","metadata":{"id":"53fe5247"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"J27S-SWvORzg"},"source":["\n","\n","# Visualize trajectories of Y_pred"],"id":"J27S-SWvORzg"},{"cell_type":"code","execution_count":null,"id":"6e8411ae","metadata":{"id":"6e8411ae"},"outputs":[],"source":["df_data_all"]},{"cell_type":"code","execution_count":null,"id":"7a2b7393","metadata":{"id":"7a2b7393"},"outputs":[],"source":["# W = pd.read_csv(f'{topdir}/sample_audio/diva_babbling_resynth/W_wavlm2divaart-202502252206.csv')\n","# b = pd.read_csv(f'{topdir}/sample_audio/diva_babbling_resynth/Wb_wavlm2divaart-202502252206.csv')\n","# W = W.iloc[:, 1:].values\n","# b = b.iloc[:, 1].values\n","# # alternatively, W and b from model if it was run\n","# W = model.coef_\n","# b = model.intercept_\n","\n","# print(df_data_all[cols_wavlm].shape)\n","# print(W.T.shape)\n","# Y_pred = df_data_all[cols_wavlm] @ W.T + b\n","\n","# alternatively\n","Y_pred = model.predict(X)\n"]},{"cell_type":"code","source":["\n","df_pred = pd.DataFrame.from_records(Y_pred)\n","df_pred.columns = [s+\"_pred\" for s in cols_diva]\n","df_data_all = pd.concat([df_data_all, df_pred], axis=1)\n","\n"],"metadata":{"id":"1TwpOLxXOlCF"},"id":"1TwpOLxXOlCF","execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_data_all"],"metadata":{"id":"mB8LP29VRd-S"},"id":"mB8LP29VRd-S","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"eda83f16","metadata":{"id":"eda83f16"},"outputs":[],"source":["# calculate sum of squares prediction value for each articulator\n","r2 = {}\n","for i, col in enumerate(cols_diva):\n","    # col = \"Jaw\"\n","    # corr = np.dot(df_data_all[col], df_data_all[col+\"_pred\"])\n","    res = df_data_all[col+\"_pred\"] - df_data_all[col]\n","    r2[col] = 1 - ((res**2).sum()) / (df_data_all[col]**2).sum()\n","    r2[col] = float(np.round(r2[col], 2))\n","# np.corrcoef(df_data_all[col+\"_pred\"], df_data_all[col])\n","r2"]},{"cell_type":"code","execution_count":null,"id":"5416f6ca","metadata":{"id":"5416f6ca"},"outputs":[],"source":["fileex = 'diva_babbling-20250224123835338'\n","df_plot = df_data_all[df_data_all['file_id']==fileex]\n","\n","fig, ax = plt.subplots(figsize=[12, 10])\n","cm = np.asarray(mpl.colormaps['tab10'].colors)\n","offset = 1.5\n","for iart,art_name in enumerate(cols_diva):\n","    cur_offset = iart*offset\n","    ax.plot(df_plot['time'], cur_offset + df_plot[art_name],         color=cm[iart % cm.shape[0], :], alpha=0.5)\n","    ax.plot(df_plot['time'], cur_offset + df_plot[art_name+\"_pred\"], color=cm[iart % cm.shape[0], :], linestyle='--')\n","\n","ax.set_yticks(offset*np.arange(len(cols_diva)), [c + \" (r2=\" + str(round(r2[c], 2)) + \")\" for c in cols_diva] )\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"42031374","metadata":{"id":"42031374"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"4cec4e3c","metadata":{"id":"4cec4e3c"},"source":["# Convert test wav file to diva art time series using learned W"]},{"cell_type":"code","execution_count":null,"id":"ec8013fd","metadata":{"id":"ec8013fd"},"outputs":[],"source":["wav_file = f'{topdir}/sample_audio/eeayeeayoo.wav'\n","# wav_file = '../sample_audio/thisisme-lat.wav'\n","\n","(fdir, fname) = os.path.split(wav_file)\n","(fname, fext) = fname.split('.')"]},{"cell_type":"code","execution_count":null,"id":"a0090898","metadata":{"id":"a0090898"},"outputs":[],"source":["\n","code_orig = coder.encode(wav_file)\n"]},{"cell_type":"code","execution_count":null,"id":"29149daa","metadata":{"id":"29149daa"},"outputs":[],"source":["# code_orig\n","wavlm  = code_orig['acoustics_wvlm']\n","divaart_predic = wavlm @ W.T + b\n","pd.DataFrame.from_records(divaart_predic).to_csv(fdir + \"/\" +  fname + '-divaart-predic-' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.csv', index=False)"]},{"cell_type":"markdown","id":"df3150bb","metadata":{"id":"df3150bb"},"source":["# Encode, resynthesize, perturb wav file"]},{"cell_type":"code","execution_count":null,"id":"00e0c6c7-e456-4cff-b573-9504d03ab88a","metadata":{"id":"00e0c6c7-e456-4cff-b573-9504d03ab88a"},"outputs":[],"source":["vars_timeseries = ['ema', 'loudness', 'pitch', 'periodicity']\n","# wav_file = '/Users/ly546/Downloads/sub-DM1033_ses-intraop_task-lombard_run-03_clip.wav'\n","code_orig = coder.encode(wav_file)\n","# code_orig = {k : v.squeeze().shape for k, v in code_orig.items() if k in ['ema', 'loudness', 'pitch', 'periodicity']}\n","# code_orig =\n","\n","code_orig = {k: (v.squeeze(axis=0) if k in vars_timeseries+[\"spk_emb\"] and v.shape[0]==1 else v) for k, v in code_orig.items()}\n","# {k : (v.shape if k in ['ema', 'loudness', 'pitch', 'periodicity', 'acoustics_wvlm', 'spk_emb'] else v) for k,v in code_orig.items()}\n"]},{"cell_type":"markdown","id":"f9122a05","metadata":{"id":"f9122a05"},"source":["### Plot the SPARC linear transform from auditory to motor space"]},{"cell_type":"code","execution_count":null,"id":"5b3fe815","metadata":{"id":"5b3fe815"},"outputs":[],"source":["W = coder.inverter.linear_model.weight.float().numpy()\n","B = coder.inverter.linear_model.bias.float().numpy()\n","fig, ax = plt.subplots(figsize=[20, 10])\n","ax.imshow(W[:, 100:200])\n","W.shape"]},{"cell_type":"code","execution_count":null,"id":"f2fa0a07","metadata":{"id":"f2fa0a07"},"outputs":[],"source":["wav = coder.decode(**code_orig)\n","sf.write(wav_file[0:-4] + '-resynth.wav', wav, coder.sr)\n","\n","# resynthesized\n","ipd.display(ipd.Audio(wav, rate=coder.sr))"]},{"cell_type":"code","execution_count":null,"id":"0ccc60c2","metadata":{"id":"0ccc60c2"},"outputs":[],"source":["def perturb_ema(ema):\n","    pert = np.zeros_like(ema)\n","    pert_t = np.arange(0, pert.shape[0]) / 50\n","\n","    t_pert_start = 0.3\n","    t_pert_end = 1.2\n","\n","    idxs_x = [s in ['TBX', 'TDX'] for i,s in enumerate(HPRC_channel_label)]\n","    idxs_y = [s in ['TBY', 'TDY'] for i,s in enumerate(HPRC_channel_label)]\n","\n","    idxs_t = (pert_t>t_pert_start) & (pert_t<t_pert_end)\n","\n","    # pert[idxs_t, idxs_x] = 0.1\n","    pert[np.ix_(idxs_t, idxs_x)] = 0.5\n","    pert[np.ix_(idxs_t, idxs_y)] = 1\n","\n","    # pert = [ for i in range(pert.shape[1])]\n","    pert = np.apply_along_axis(lambda x : sp.signal.savgol_filter(x, 5, 2), axis=0, arr=pert)\n","\n","    # plt.imshow(pert)\n","    # np.max(ema, axis=0)\n","    return ema + pert"]},{"cell_type":"code","execution_count":null,"id":"049fa173-cd75-4237-b317-b9701e258791","metadata":{"id":"049fa173-cd75-4237-b317-b9701e258791"},"outputs":[],"source":["code = copy.deepcopy(code_orig)\n","# code = code_orig.copy()\n","\n","code['ema'] = perturb_ema(code_orig['ema'])\n","wav = coder.decode(**code)\n","sf.write(wav_file[0:-4] + '-resynth-pert.wav', wav, coder.sr)\n","\n","# resynthesized\n","ipd.display(ipd.Audio(wav, rate=coder.sr))"]},{"cell_type":"code","execution_count":null,"id":"2e6ed050","metadata":{"id":"2e6ed050"},"outputs":[],"source":["# extend the perturbation\n","code = copy.deepcopy(code_orig)\n","\n","idx_split = 44\n","def extendmat(m, idx_split, nrpt, axis=0):\n","    return np.concatenate((m[0:idx_split, :], np.tile(m[idx_split, :], (nrpt, 1)), m[idx_split:-1, :]), axis=axis)\n","\n","code =  {k: (extendmat(v, idx_split, 100) if k in ['ema', 'loudness', 'pitch', 'periodicity'] else v) for k, v in code.items()}\n","# {k: extendmat(v, idx_split, 20) for k, v in code.items()}\n","# {k: (v.shape if k in vars_timeseries else 1) for k, v in code.items()}\n","\n","wav = coder.decode(**code)\n","sf.write(wav_file[0:-4] + '-resynth-extended.wav', wav, coder.sr)\n","\n","ipd.display(ipd.Audio(wav, rate=coder.sr))"]},{"cell_type":"code","execution_count":null,"id":"775a7fe0","metadata":{"id":"775a7fe0"},"outputs":[],"source":["# test the minimal amount of data we can pass to the synthesizer\n","code = copy.deepcopy(code_orig)\n","\n","idx_width = 1\n","idx_center = 40\n","def slicemat(m, idx_width, idx_center):\n","    idxs = np.arange(idx_width) + idx_center\n","    return m[idxs, :]\n","\n","code =  {k: (slicemat(v, idx_width, idx_center) if k in ['ema', 'loudness', 'pitch', 'periodicity'] else v) for k, v in code.items()}\n","# {k: extendmat(v, idx_split, 20) for k, v in code.items()}\n","# {k: (v.shape if k in vars_timeseries else 1) for k, v in code.items()}\n"]},{"cell_type":"code","execution_count":null,"id":"7a81e991","metadata":{"id":"7a81e991"},"outputs":[],"source":["\n","wav = coder.decode(**code)\n","print(f'Duration: {len(wav) / coder.sr}')\n","sf.write(wav_file[0:-4] + '-sliced.wav', wav, coder.sr)\n","\n","ipd.display(ipd.Audio(wav, rate=coder.sr))"]},{"cell_type":"code","execution_count":null,"id":"174cda31-3b6d-4add-9c99-3df8f96165f6","metadata":{"scrolled":true,"id":"174cda31-3b6d-4add-9c99-3df8f96165f6"},"outputs":[],"source":["# ground truth reference\n","wavt,tsr = sf.read(wav_file)\n","ipd.display(ipd.Audio(wavt, rate=tsr))"]},{"cell_type":"markdown","id":"444a51a7","metadata":{"id":"444a51a7"},"source":["# Detect audio errors from bed to bad, apply to motor command"]},{"cell_type":"code","execution_count":null,"id":"dd907bfb","metadata":{"id":"dd907bfb"},"outputs":[],"source":["vars_timeseries = ['ema', 'loudness', 'pitch', 'periodicity']\n","\n","wav_file_bed  = '../sample_audio/bed-lat.wav'\n","wav_file_bAd  = '../sample_audio/bad-lat.wav'\n","\n","# trim wav files to make them equal length\n","wav_bed,wav_bed_sr = sf.read(wav_file_bed)\n","wav_bAd,wav_bAd_sr = sf.read(wav_file_bAd)\n","\n","if len(wav_bed)>len(wav_bAd):\n","    wav_bed = wav_bed[0:len(wav_bAd)]\n","else:\n","    wav_bAd = wav_bAd[0:len(wav_bed)]\n","\n","print(len(wav_bed), len(wav_bAd))\n","sf.write(wav_file_bed[0:-4] + '-trim.wav', wav_bed, wav_bed_sr)\n","sf.write(wav_file_bAd[0:-4] + '-trim.wav', wav_bAd, wav_bed_sr)\n"]},{"cell_type":"code","execution_count":null,"id":"bdfa276f","metadata":{"id":"bdfa276f"},"outputs":[],"source":["wav_file_bed  = '../sample_audio/bed-lat-trim.wav'\n","wav_file_bAd  = '../sample_audio/bad-lat-trim.wav'\n","\n","def squeeze_code(code_orig):\n","    return {k: (v.squeeze(axis=0) if k in vars_timeseries+[\"spk_emb\"] and v.shape[0]==1 else v) for k, v in code_orig.items()}\n","\n","codes = [coder.encode(f) for f in [wav_file_bed, wav_file_bAd]]\n","codes = [squeeze_code(c) for c in codes]\n"]},{"cell_type":"code","execution_count":null,"id":"4805c1f2","metadata":{"id":"4805c1f2"},"outputs":[],"source":["# get error traces\n","W = coder.inverter.linear_model.weight.float().numpy()\n","B = coder.inverter.linear_model.bias.float().numpy()\n","\n","A_error = codes[1]['acoustics_wvlm'] - codes[0]['acoustics_wvlm']\n","M_error = np.dot(A_error, W.T) + B\n","M_error = M_error\n"]},{"cell_type":"code","execution_count":null,"id":"c7a9e9dd","metadata":{"id":"c7a9e9dd"},"outputs":[],"source":["code_new = copy.deepcopy(codes[0])\n","code_new['ema'] = codes[0]['ema'] + M_error\n","\n","codes.append(code_new)"]},{"cell_type":"code","execution_count":null,"id":"69bd19fb","metadata":{"id":"69bd19fb"},"outputs":[],"source":["fig,ax = plt.subplots(2,1, figsize=(5,10), sharex=True)\n","\n","ax[0].plot(np.arange(0, wav_bed.size) / sr, wav_bed)\n","\n","for code, color in zip(codes, ['tab:red', 'tab:blue','tab:purple']):\n","    print(color)\n","    plot_art(ax[1], (code['ema']), color=color, gap=6, alpha=0.5, lw=2)\n","# plot_art(ax[1], perturb_ema(code['ema']), color='C0', gap=6, alpha=0.5, lw=2)\n","# plot_art(ax[1], (code2['ema']), color='C0', gap=6, alpha=0.5, lw=1)\n","\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"0737bf16","metadata":{"id":"0737bf16"},"outputs":[],"source":["wavs_resynth = [coder.decode(**c) for c in codes]\n","\n","sf.write(wav_file_bed[0:-4] + '-resynth.wav', wavs_resynth[0], coder.sr)\n","sf.write(wav_file_bAd[0:-4] + '-resynth.wav', wavs_resynth[1], coder.sr)\n","sf.write(wav_file_bed[0:-4] + '-pert-towards-bad-resynth.wav', wavs_resynth[2], coder.sr)\n"]},{"cell_type":"code","execution_count":null,"id":"4b07191b","metadata":{"id":"4b07191b"},"outputs":[],"source":["# listen to all three:\n","ipd.display(ipd.Audio(wavs_resynth[0], rate=coder.sr))\n","ipd.display(ipd.Audio(wavs_resynth[1], rate=coder.sr))\n","ipd.display(ipd.Audio(wavs_resynth[2], rate=coder.sr))\n"]},{"cell_type":"markdown","id":"c6e16490-ffb9-4431-b602-e75f07d7ea41","metadata":{"tags":[],"id":"c6e16490-ffb9-4431-b602-e75f07d7ea41"},"source":["# Voice Conversion"]},{"cell_type":"code","execution_count":null,"id":"25d16905-e5b3-4690-b879-b2c7258d250c","metadata":{"id":"25d16905-e5b3-4690-b879-b2c7258d250c"},"outputs":[],"source":["# src_wav_file = '/Users/ly546/Downloads/sub-DM1033_ses-intraop_task-lombard_run-03_clip.wav' # '/Users/ly546/Downloads/sub-DM1033_ses-intraop_task-lombard_run-03_clip.wav'\n","# src_wav_file = '../sample_audio/sub-DM1033_ses-intraop_task-lombard_run-03_directionalmicaec-start-99s.wav'\n","src_wav_file = '../sample_audio/thisisme-lat.wav'\n","\n","# targspkemb_wav_file = '../sample_audio/be2d-chin-trim.wav'\n","targspkemb_wav_file = '../sample_audio/thisisme-fran.wav'\n"]},{"cell_type":"code","execution_count":null,"id":"f004f691-f9ee-446a-ba06-05a5bd044fef","metadata":{"id":"f004f691-f9ee-446a-ba06-05a5bd044fef"},"outputs":[],"source":["converted_wav = coder.convert(src_wav_file, targspkemb_wav_file)\n","ipd.display(ipd.Audio(converted_wav, rate=coder.sr))\n","\n","sf.write(src_wav_file[0:-4] + '_voice-from_' + os.path.split(targspkemb_wav_file)[1][0:-4]  + '-resynth.wav', converted_wav, coder.sr)\n"]},{"cell_type":"code","execution_count":null,"id":"43e97d50-2ebf-4fb4-bd83-fc673b2b2609","metadata":{"id":"43e97d50-2ebf-4fb4-bd83-fc673b2b2609"},"outputs":[],"source":["src_code = coder.encode(src_wav_file)"]},{"cell_type":"code","execution_count":null,"id":"37d1b009-bd78-42ce-8c31-c925c606dcf3","metadata":{"id":"37d1b009-bd78-42ce-8c31-c925c606dcf3"},"outputs":[],"source":["converted_code = coder.encode(converted_wav)"]},{"cell_type":"code","execution_count":null,"id":"d7810cf9-6881-48aa-bc28-134c37c8453e","metadata":{"id":"d7810cf9-6881-48aa-bc28-134c37c8453e"},"outputs":[],"source":["# Articulatory traces remain consistent after voice conversion.\n","plt.plot(src_code['ema'][:,5])\n","plt.plot(converted_code['ema'][:,5])"]},{"cell_type":"code","execution_count":null,"id":"a89fe8c5-47f8-4bb1-8924-a02809c7d4ad","metadata":{"id":"a89fe8c5-47f8-4bb1-8924-a02809c7d4ad"},"outputs":[],"source":["# source audio\n","src_wav,sr = sf.read(src_wav_file)\n","ipd.display(ipd.Audio(src_wav, rate=sr))"]},{"cell_type":"code","execution_count":null,"id":"727464b9-1946-4a4e-a97a-cc285626f3b5","metadata":{"id":"727464b9-1946-4a4e-a97a-cc285626f3b5"},"outputs":[],"source":["# target audio\n","trg_wav,sr = sf.read(targspkemb_wav_file)\n","ipd.display(ipd.Audio(trg_wav, rate=sr))"]},{"cell_type":"markdown","id":"d4f9b1fd-6420-4162-8e49-3b32d7707650","metadata":{"id":"d4f9b1fd-6420-4162-8e49-3b32d7707650"},"source":["# Unseen Language"]},{"cell_type":"code","execution_count":null,"id":"c8c1aaf0-2906-47d6-978a-8e63a20ccf4e","metadata":{"id":"c8c1aaf0-2906-47d6-978a-8e63a20ccf4e"},"outputs":[],"source":["wav_file = \"../sample_audio/italian.wav\""]},{"cell_type":"code","execution_count":null,"id":"fa5c5efd-bb1c-476c-8bd1-e17e2e671e80","metadata":{"id":"fa5c5efd-bb1c-476c-8bd1-e17e2e671e80"},"outputs":[],"source":["code = coder.encode(wav_file)"]},{"cell_type":"code","execution_count":null,"id":"7cd2b558-2579-4a97-b7b1-98a0a9737f7d","metadata":{"id":"7cd2b558-2579-4a97-b7b1-98a0a9737f7d"},"outputs":[],"source":["wav = coder.decode(**code)"]},{"cell_type":"code","execution_count":null,"id":"21b91f3b-7f56-47a8-be5a-b19cac846ea8","metadata":{"id":"21b91f3b-7f56-47a8-be5a-b19cac846ea8"},"outputs":[],"source":["# resynthesized\n","ipd.display(ipd.Audio(wav, rate=coder.sr))"]},{"cell_type":"code","execution_count":null,"id":"c57fdbbb-ced2-433a-9ed1-a02c1e56bca7","metadata":{"id":"c57fdbbb-ced2-433a-9ed1-a02c1e56bca7"},"outputs":[],"source":["# ground truth reference\n","wavt,tsr = sf.read(wav_file)\n","ipd.display(ipd.Audio(wavt, rate=tsr))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.21"},"colab":{"provenance":[],"gpuType":"V28"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}